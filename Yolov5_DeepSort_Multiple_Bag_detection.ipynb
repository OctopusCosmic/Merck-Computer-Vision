{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolov5 DeepSort Multiple Bag detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OctopusCosmic/Merck-Computer-Vision/blob/main/Yolov5_DeepSort_Multiple_Bag_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIGuIpRFAo18"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taGCP-gCgqX8",
        "outputId": "60dc5863-b5eb-4383-9984-3ab2899c9fa3"
      },
      "source": [
        "!git clone --recurse-submodules https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch.git  # clone repo\n",
        "%cd Yolov5_DeepSort_Pytorch\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.10.0+cu111 (CPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JQRVPMtA9Cr"
      },
      "source": [
        "# Crop data\n",
        "\n",
        "Get test video from repo and extract the first 2 seconds of it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Acf_nRZ7yS6",
        "outputId": "e80d117c-4f8a-47d2-96b8-5d644ca08fb5"
      },
      "source": [
        "# get yolov5m model trained on the crowd-human dataset\n",
        "#!wget -nc https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/releases/download/v.2.0/crowdhuman_yolov5m.pt -O /content/Yolov5_DeepSort_Pytorch/yolov5/weights/crowdhuman_yolov5m.pt\n",
        "#!wget -nc /content/best\\ (3).pt -O /content/Yolov5_DeepSort_Pytorch/yolov5/weights/bag_yolov5m.pt\n",
        "\n",
        "# get the test video from the repo\n",
        "#!wget -nc https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/releases/download/v.2.0/test.avi\n",
        "# extract 3 seconds worth of video frames of it\n",
        "\n",
        "#!y | ffmpeg -ss 00:00:00 -i test.avi -t 00:00:02 -c copy out.avi\n",
        "!y | ffmpeg -ss 00:00:00 -i /content/Multiple_Bags_film1.mp4 -t 00:00:02 -c copy out.mp4"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: y: command not found\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/Multiple_Bags_film1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 1\n",
            "    compatible_brands: isommp41mp42\n",
            "    creation_time   : 2022-01-28T03:08:10.000000Z\n",
            "    copyright       : \n",
            "    copyright-eng   : \n",
            "  Duration: 00:01:06.90, start: 0.000000, bitrate: 1341 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1200x720, 1338 kb/s, 29.82 fps, 29.97 tbr, 600 tbn, 1200 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-01-28T03:08:10.000000Z\n",
            "      handler_name    : Core Media Video\n",
            "File 'out.mp4' already exists. Overwrite ? [y/N] \u001b[4;31mNot overwriting - exiting\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqIP5shr9HQd"
      },
      "source": [
        "## Run inference on video\n",
        "\n",
        "The ``cv2.imshow()`` and ``cv.imshow()`` functions from the [opencv-python](https://github.com/skvark/opencv-python) package are incompatible with Jupyter notebook; see https://github.com/jupyter/notebook/issues/3935. \n",
        "\n",
        "Hence we chose to save it to file in this notebook. Locally you can use the ``--show-vid`` flag in order visualize the tracking in real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yEraJfKhBku",
        "outputId": "f69fd0d9-c6b8-4438-bb24-58193ab3b1e8"
      },
      "source": [
        "#!python track.py --yolo_model /content/Yolov5_DeepSort_Pytorch/yolov5/weights/crowdhuman_yolov5m.pt --source out.avi --save-vid\n",
        "!python track.py --yolo_model /content/bag_model.pt --source out.mp4 --save-vid"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep_sort/deep/reid/torchreid/metrics/rank.py:12: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
            "  'Cython evaluation (very fast so highly recommended) is '\n",
            "YOLOv5 ðŸš€ v6.0-159-gdb6ec66 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Successfully loaded imagenet pretrained weights from \"/root/.cache/torch/checkpoints/osnet_x0_25_imagenet.pth\"\n",
            "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
            "Model: osnet_x0_25\n",
            "- params: 203,568\n",
            "- flops: 82,316,000\n",
            "YOLOv5 ðŸš€ v6.0-159-gdb6ec66 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7015519 parameters, 0 gradients\n",
            "video 1/1 (1/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.311s), DeepSort:(0.046s)\n",
            "video 1/1 (2/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.298s), DeepSort:(0.059s)\n",
            "video 1/1 (3/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.292s), DeepSort:(0.047s)\n",
            "video 1/1 (4/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.290s), DeepSort:(0.049s)\n",
            "video 1/1 (5/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.281s), DeepSort:(0.046s)\n",
            "video 1/1 (6/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.275s), DeepSort:(0.045s)\n",
            "video 1/1 (7/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.282s), DeepSort:(0.049s)\n",
            "video 1/1 (8/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.281s), DeepSort:(0.049s)\n",
            "video 1/1 (9/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.278s), DeepSort:(0.048s)\n",
            "video 1/1 (10/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.287s), DeepSort:(0.047s)\n",
            "video 1/1 (11/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.049s)\n",
            "video 1/1 (12/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.045s)\n",
            "video 1/1 (13/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.285s), DeepSort:(0.052s)\n",
            "video 1/1 (14/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.276s), DeepSort:(0.048s)\n",
            "video 1/1 (15/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.047s)\n",
            "video 1/1 (16/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.294s), DeepSort:(0.046s)\n",
            "video 1/1 (17/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.048s)\n",
            "video 1/1 (18/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.293s), DeepSort:(0.048s)\n",
            "video 1/1 (19/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.298s), DeepSort:(0.048s)\n",
            "video 1/1 (20/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.286s), DeepSort:(0.048s)\n",
            "video 1/1 (21/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.046s)\n",
            "video 1/1 (22/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.288s), DeepSort:(0.048s)\n",
            "video 1/1 (23/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.284s), DeepSort:(0.046s)\n",
            "video 1/1 (24/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.281s), DeepSort:(0.053s)\n",
            "video 1/1 (25/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.288s), DeepSort:(0.047s)\n",
            "video 1/1 (26/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.278s), DeepSort:(0.049s)\n",
            "video 1/1 (27/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.280s), DeepSort:(0.049s)\n",
            "video 1/1 (28/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.047s)\n",
            "video 1/1 (29/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.279s), DeepSort:(0.045s)\n",
            "video 1/1 (30/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.272s), DeepSort:(0.053s)\n",
            "video 1/1 (31/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.287s), DeepSort:(0.046s)\n",
            "video 1/1 (32/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.046s)\n",
            "video 1/1 (33/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.284s), DeepSort:(0.049s)\n",
            "video 1/1 (34/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.302s), DeepSort:(0.049s)\n",
            "video 1/1 (35/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.322s), DeepSort:(0.049s)\n",
            "video 1/1 (36/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.287s), DeepSort:(0.048s)\n",
            "video 1/1 (37/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.279s), DeepSort:(0.051s)\n",
            "video 1/1 (38/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.281s), DeepSort:(0.054s)\n",
            "video 1/1 (39/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.351s), DeepSort:(0.060s)\n",
            "video 1/1 (40/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.285s), DeepSort:(0.052s)\n",
            "video 1/1 (41/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.283s), DeepSort:(0.048s)\n",
            "video 1/1 (42/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.327s), DeepSort:(0.055s)\n",
            "video 1/1 (43/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 2 Sugar bags, Done. YOLO:(0.287s), DeepSort:(0.073s)\n",
            "video 1/1 (44/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.286s), DeepSort:(0.045s)\n",
            "video 1/1 (45/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.279s), DeepSort:(0.046s)\n",
            "video 1/1 (46/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.278s), DeepSort:(0.048s)\n",
            "video 1/1 (47/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.289s), DeepSort:(0.049s)\n",
            "video 1/1 (48/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.284s), DeepSort:(0.045s)\n",
            "video 1/1 (49/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.273s), DeepSort:(0.043s)\n",
            "video 1/1 (50/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.276s), DeepSort:(0.046s)\n",
            "video 1/1 (51/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.275s), DeepSort:(0.043s)\n",
            "video 1/1 (52/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.271s), DeepSort:(0.046s)\n",
            "video 1/1 (53/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.279s), DeepSort:(0.049s)\n",
            "video 1/1 (54/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.287s), DeepSort:(0.050s)\n",
            "video 1/1 (55/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 2 Sugar bags, Done. YOLO:(0.281s), DeepSort:(0.048s)\n",
            "video 1/1 (56/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.285s), DeepSort:(0.050s)\n",
            "video 1/1 (57/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.279s), DeepSort:(0.048s)\n",
            "video 1/1 (58/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.278s), DeepSort:(0.051s)\n",
            "video 1/1 (59/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.281s), DeepSort:(0.046s)\n",
            "video 1/1 (60/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 2 Sugar bags, Done. YOLO:(0.279s), DeepSort:(0.050s)\n",
            "video 1/1 (61/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.278s), DeepSort:(0.051s)\n",
            "video 1/1 (62/62) /content/Yolov5_DeepSort_Pytorch/out.mp4: 384x640 1 Flour bag, 1 Sugar bag, Done. YOLO:(0.276s), DeepSort:(0.048s)\n",
            "Speed: 0.9ms pre-process, 286.0ms inference, 0.7ms NMS, 48.9ms deep sort update         per image at shape (1, 3, 640, 640)\n",
            "Results saved to runs/track/exp2/out.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd-CFrVGBoEU"
      },
      "source": [
        "# Show results\n",
        "\n",
        "https://stackoverflow.com/questions/60977179/how-to-play-avi-file-in-google-colab\n",
        "\n",
        "Convert avi to mp4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-4tlUaCBjDC"
      },
      "source": [
        "#!ffmpeg -i /content/Yolov5_DeepSort_Pytorch/runs/track/exp/out.avi output.mp4"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7XAlRteC9qI"
      },
      "source": [
        "Get the file content into data_url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ObuFb7dBwxK"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/Yolov5_DeepSort_Pytorch/runs/track/exp/out.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLvggIUZDC6R"
      },
      "source": [
        "Display it with HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyXr0xsZB897"
      },
      "source": [
        "HTML(\"\"\"\n",
        "<video controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xOS3FTIMloGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}